default:
	@just --list


export:
	uv run ../benchmarks/import.py --csv test_results.csv --db ../benchmarks/metrics.db

# Register functions once before running sequential workloads
register-functions address="localhost:50050":
	k6 run --quiet -e ADDRESS={{address}} register-functions.js > function_ids.json
	@echo "Functions registered and IDs saved to function_ids.json"

# Run multiple short sequential workloads to avoid gRPC connection buildup
run-sequential total_runs="10" run_duration="2m" seed="12345" address="localhost:50050":
	#!/bin/bash
	set -e
	echo "{{run_duration}}"
	echo "{{total_runs}}"
	echo "{{seed}}"
	echo "{{address}}"
	total_runs=$(echo "{{total_runs}}")
	run_duration=$(echo "{{run_duration}}")
	echo "Running $total_runs sequential workloads of $run_duration each"
	
	# Clean up previous results
	rm -f test_results_*.csv generated_scenarios_*.json
	
	# Ensure functions are registered
	if [ ! -f function_ids.json ]; then
		echo "Function IDs not found, registering functions..."
		just register-functions {{address}}
	fi
	
	# Load function IDs from JSON file
	BFS_FUNCTION_ID=$(jq -r '.functionIds.bfs' function_ids.json)
	ECHO_FUNCTION_ID=$(jq -r '.functionIds.echo' function_ids.json)
	THUMBNAILER_FUNCTION_ID=$(jq -r '.functionIds.thumbnailer' function_ids.json)
	echo "BFS_FUNCTION_ID=$BFS_FUNCTION_ID"
	echo "ECHO_FUNCTION_ID=$ECHO_FUNCTION_ID"
	echo "THUMBNAILER_FUNCTION_ID=$THUMBNAILER_FUNCTION_ID"
	
	# Run sequential workloads
	for ((i=1; i<=total_runs; i++)); do
		echo "Running workload $i/$total_runs..."
		
		k6 run \
		--quiet \
		--out csv=test_results_run_${i}.csv \
		-e WORKLOAD_SEED={{seed}} \
		-e PERSIST_GENERATION=true \
		-e TOTAL_TEST_DURATION=${run_duration} \
		-e FUNCTION_TIMEOUT_SECONDS=30 \
		-e MIN_PREALLOCATED_VUS=10 \
		-e MAX_PREALLOCATED_VUS=12 \
		-e MIN_MAX_VUS=10000 \
		-e MAX_MAX_VUS=11000 \
		-e RAMPING_START_RATE_MIN=1 \
		-e RAMPING_START_RATE_MAX=50 \
		-e BFS_MIN_SCENARIOS=3 \
		-e BFS_MAX_SCENARIOS=4 \
		-e BFS_CONSTANT_SCENARIOS_RATIO=0.6 \
		-e BFS_CONSTANT_RATE_MIN=350 \
		-e BFS_CONSTANT_RATE_MAX=450 \
		-e BFS_BURST_TARGET_RATE_MIN=300 \
		-e BFS_BURST_TARGET_RATE_MAX=350 \
		-e ECHO_MIN_SCENARIOS=3 \
		-e ECHO_MAX_SCENARIOS=4 \
		-e ECHO_CONSTANT_SCENARIOS_RATIO=0.5 \
		-e ECHO_CONSTANT_RATE_MIN=1100 \
		-e ECHO_CONSTANT_RATE_MAX=1500 \
		-e ECHO_BURST_TARGET_RATE_MIN=2000 \
		-e ECHO_BURST_TARGET_RATE_MAX=3000 \
		-e THUMBNAILER_MIN_SCENARIOS=3 \
		-e THUMBNAILER_MAX_SCENARIOS=4 \
		-e THUMBNAILER_CONSTANT_SCENARIOS_RATIO=0.8 \
		-e THUMBNAILER_CONSTANT_RATE_MIN=450 \
		-e THUMBNAILER_CONSTANT_RATE_MAX=550 \
		-e THUMBNAILER_BURST_TARGET_RATE_MIN=600 \
		-e THUMBNAILER_BURST_TARGET_RATE_MAX=1000 \
		-e ADDRESS={{address}} \
		-e RUN_ID=${i} \
		-e BFS_FUNCTION_ID=$BFS_FUNCTION_ID \
		-e ECHO_FUNCTION_ID=$ECHO_FUNCTION_ID \
		-e THUMBNAILER_FUNCTION_ID=$THUMBNAILER_FUNCTION_ID \
		script-sequential.js > generated_scenarios_run_${i}.json
		
		# Add a small delay between runs to let connections settle
		sleep 1
	done
	echo "Sequential workload completed successfully!"

# Merge results from multiple runs
merge-results num_runs:
	#!/usr/bin/env bash
	set -e
	
	# Merge CSV files
	echo "Merging CSV files..."
	head -n 1 test_results_run_1.csv > test_results.csv
	for ((i=1; i<=num_runs; i++)); do
		tail -n +2 test_results_run_${i}.csv >> test_results.csv
	done
	
	# Create combined scenarios JSON
	echo "Merging scenario metadata..."
	echo '{"runs": [' > generated_scenarios.json
	for ((i=1; i<=num_runs; i++)); do
		cat generated_scenarios_run_${i}.json
		if [ $i -lt num_runs ]; then
			echo ","
		fi
	done >> generated_scenarios.json
	echo ']}' >> generated_scenarios.json
	
	# Clean up individual run files
	rm -f test_results_run_*.csv generated_scenarios_run_*.json
	
	echo "Results merged into test_results.csv and generated_scenarios.json"

# Export merged results to database
export-sequential:
	uv run ../benchmarks/import.py --csv test_results.csv --db ../benchmarks/metrics.db --json generated_scenarios.json

# run a seeded load generation with parameters (original single run)
run time="2m" seed="12345" address="localhost:50050":
	k6 run \
	--quiet \
	--out csv=test_results.csv \
	-e WORKLOAD_SEED={{seed}} \
	-e PERSIST_GENERATION=true \
	-e TOTAL_TEST_DURATION={{time}} \
	-e FUNCTION_TIMEOUT_SECONDS=30 \
	-e MIN_PREALLOCATED_VUS=10 \
	-e MAX_PREALLOCATED_VUS=12 \
	-e MIN_MAX_VUS=10000 \
	-e MAX_MAX_VUS=11000 \
	-e RAMPING_START_RATE_MIN=1 \
	-e RAMPING_START_RATE_MAX=50 \
	-e BFS_MIN_SCENARIOS=3 \
	-e BFS_MAX_SCENARIOS=4 \
	-e BFS_CONSTANT_SCENARIOS_RATIO=0.6 \
	-e BFS_CONSTANT_RATE_MIN=350 \
	-e BFS_CONSTANT_RATE_MAX=450 \
	-e BFS_BURST_TARGET_RATE_MIN=300 \
	-e BFS_BURST_TARGET_RATE_MAX=350 \
	-e ECHO_MIN_SCENARIOS=3 \
	-e ECHO_MAX_SCENARIOS=4 \
	-e ECHO_CONSTANT_SCENARIOS_RATIO=0.5 \
	-e ECHO_CONSTANT_RATE_MIN=1100 \
	-e ECHO_CONSTANT_RATE_MAX=1500 \
	-e ECHO_BURST_TARGET_RATE_MIN=2000 \
	-e ECHO_BURST_TARGET_RATE_MAX=3000 \
	-e THUMBNAILER_MIN_SCENARIOS=3 \
	-e THUMBNAILER_MAX_SCENARIOS=4 \
	-e THUMBNAILER_CONSTANT_SCENARIOS_RATIO=0.8 \
	-e THUMBNAILER_CONSTANT_RATE_MIN=450 \
	-e THUMBNAILER_CONSTANT_RATE_MAX=550 \
	-e THUMBNAILER_BURST_TARGET_RATE_MIN=600 \
	-e THUMBNAILER_BURST_TARGET_RATE_MAX=1000 \
	-e ADDRESS={{address}} \
	script.js 1> generated_scenarios.json 2> stderr_output.txt && \
	jq --arg bfs "$(grep -o "bfsFunctionId= [^\"]*" stderr_output.txt | sed 's/functionId= //' | awk '{print $2}')" \
	   --arg echo "$(grep -o "echoFunctionId= [^\"]*" stderr_output.txt | sed 's/functionId= //' | awk '{print $2}')" \
	   --arg thumb "$(grep -o "thumbnailerFunctionId= [^\"]*" stderr_output.txt | sed 's/functionId= //' | awk '{print $2}')" \
	   '.metadata += {bfsFunctionId: $bfs, echoFunctionId: $echo, thumbnailerFunctionId: $thumb}' \
	   generated_scenarios.json > tmp.json && mv tmp.json generated_scenarios.json && rm stderr_output.txt

# dont judge me for the monster above... there is no way to get data out of the setup function in k6
# so we have to do this.